#### 安装环境

![1713257853961](image/HW5/1713257853961.png)

#### 创建和运行pipeline_transformer

![1713258228177](image/HW5/1713258228177.png)

#### 直接运行模型

![1713258552162](image/HW5/1713258552162.png)

花费时间较长，大约5min左右

###### 命令行对话

![1713259930495](image/HW5/1713259930495.png)

通过资源监视器可以看到资源显存已经被吃满8g

改变 `--cache-max-entry-count`参数，设为0.5。

![1713275720497](image/HW5/1713275720497.png)

但是生成token的速度进一步延长了，体感上两倍不止，下图为限制缓存后的输出

![1713277592422](image/HW5/1713277592422.png)

###### 量化

![1713259532214](image/HW5/1713259532214.png)

###### 显存占用明显降低

![1713335215913](image/HW5/1713335215913.png)

#### API服务器：

在完成端口转发和后台启动后

![1713336198474](image/HW5/1713336198474.png)

gradio前端

![1713336497863](image/HW5/1713336497863.png)

Python集成代码运行

![1713348705681](image/HW5/1713348705681.png)

修改代码

![1713348725668](image/HW5/1713348725668.png)

速度有明显提升

![1713348757137](image/HW5/1713348757137.png)

###### llava多模态运行

![1713350393786](image/HW5/1713350393786.png)

gradio运行llava

![1713358180918](image/HW5/1713358180918.png)
